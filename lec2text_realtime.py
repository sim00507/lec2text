import os
import subprocess
import whisper
import math
from pydub import AudioSegment

# ğŸ”§ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í•  ì„¤ì •
SEGMENT_DURATION = 15  # ì´ˆ ë‹¨ìœ„

# ğŸ mp4 íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
mp4_files = [f for f in os.listdir() if f.endswith(".mp4")]
if not mp4_files:
    print("âŒ í˜„ì¬ ë””ë ‰í„°ë¦¬ì— .mp4 íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    exit()

print("ë³€í™˜í•  .mp4 íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”:")
for i, file in enumerate(mp4_files):
    print(f"{i + 1}. {file}")
choice = int(input("ë²ˆí˜¸ ì…ë ¥: ")) - 1

input_video = mp4_files[choice]
base_name = os.path.splitext(input_video)[0]
save_dir = os.path.join("result", base_name)
os.makedirs(save_dir, exist_ok=True)

output_mp3 = os.path.join(save_dir, f"{base_name}.mp3")
output_txt = os.path.join(save_dir, f"{base_name}.txt")

# ğŸ”„ MP4 â†’ MP3 ë³€í™˜
print(f"\nğŸ”„ '{input_video}' â†’ '{output_mp3}' ë³€í™˜ ì¤‘...")
subprocess.run([
    "ffmpeg", "-i", input_video, "-q:a", "0", "-map", "a", output_mp3
], check=True)

# ğŸ§  Whisper ëª¨ë¸ ë¡œë“œ (GPU)
print("ğŸ§  Whisper ëª¨ë¸ ë¡œë”© ì¤‘ (GPU)...")
model = whisper.load_model("medium", device="cuda")

# ğŸš€ ë°©ì‹ ì„ íƒ
print("\nì›í•˜ëŠ” ë³€í™˜ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”:")
print("1. ì „ì²´ íŒŒì¼ì„ í•œ ë²ˆì— ì²˜ë¦¬ (transcribe)")
print("2. 15ì´ˆ ë‹¨ìœ„ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë‚˜ëˆ ì„œ ì²˜ë¦¬ (ì§„í–‰ ìƒí™© í™•ì¸ ê°€ëŠ¥)")
mode = input("ë²ˆí˜¸ ì…ë ¥: ")

# ===================================
# âœ… MODE 1: í•œ ë²ˆì— ì „ì²´ ë³€í™˜
# ===================================
if mode == "1":
    print("ğŸ§ ìŒì„± í…ìŠ¤íŠ¸í™” ì§„í–‰ ì¤‘...")
    result = model.transcribe(output_mp3, language="ko", fp16=True)
    
    for i, segment in enumerate(result["segments"]):
        print(f"[{i+1}] ({segment['start']:.2f}s ~ {segment['end']:.2f}s): {segment['text']}")

    with open(output_txt, "w", encoding="utf-8") as f:
        f.write(result["text"])

# ===================================
# âœ… MODE 2: ì„¸ê·¸ë¨¼íŠ¸ ì‹¤ì‹œê°„ ì¶œë ¥
# ===================================
elif mode == "2":
    print("âœ‚ï¸ ì˜¤ë””ì˜¤ ë¶„í•  ë° ì‹¤ì‹œê°„ ì¶œë ¥ ì‹œì‘...\n")
    audio = AudioSegment.from_file(output_mp3)
    total_duration = math.ceil(len(audio) / 1000)
    full_text = ""

    for i, start in enumerate(range(0, total_duration, SEGMENT_DURATION)):
        end = min(start + SEGMENT_DURATION, total_duration)
        segment_audio = audio[start * 1000:end * 1000]
        temp_path = os.path.join(save_dir, f"temp_{i}.mp3")
        segment_audio.export(temp_path, format="mp3")

        result = model.transcribe(temp_path, language="ko", fp16=True)
        print(f"[{i+1}] ({start}s ~ {end}s): {result['text']}")
        full_text += result["text"] + "\n"

        os.remove(temp_path)

    with open(output_txt, "w", encoding="utf-8") as f:
        f.write(full_text)

else:
    print("âŒ ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    exit()

print(f"\nâœ… ë³€í™˜ ì™„ë£Œ! ê²°ê³¼ í…ìŠ¤íŠ¸ëŠ” '{output_txt}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
